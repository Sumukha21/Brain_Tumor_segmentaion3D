{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Description:\n \n### Image types: \n* Native T1-weighted (T1): This scan is obtained using a standard T1-weighted imaging sequence, which uses a short TR (repetition time) and a short TE (echo time) to provide high-resolution images of the brain tissue. This sequence highlights the differences in tissue types based on their contrast with the surrounding tissues.\n\n* Post-contrast T1-weighted (T1Gd): This scan is obtained using a T1-weighted imaging sequence after the administration of a contrast agent such as Gadolinium. The contrast agent is injected intravenously and is taken up by cells with a disrupted blood-brain barrier, which is a common characteristic of brain tumors. This sequence highlights the regions of the brain with a disrupted blood-brain barrier, such as enhancing tumor regions.\n\n* T2-weighted (T2): This scan is obtained using a T2-weighted imaging sequence, which uses a long TR and a long TE to provide a more detailed view of the brain tissue. This sequence highlights subtle differences in tissue types that are not visible on T1 scans.\n\n* T2 Fluid Attenuated Inversion Recovery (T2-FLAIR): This scan is obtained using a T2-weighted imaging sequence that is modified to suppress the signal from cerebrospinal fluid (CSF). This is achieved by using an inversion recovery pulse before the T2-weighted acquisition. This sequence is useful for distinguishing between edema and other types of brain tissue because the CSF signal is suppressed.\n\n### Segmentation Classes:\n* label 0: No tumor\n* label 1: necrotic tumor core (Visible in T2): This class represents the core of the tumor, which is composed of necrotic tissue and non-enhancing tumor cells.\n* label 2: the peritumoral edematous/invaded tissue (Visible in flair):  This class represents the edema, or swelling, that occurs around the tumor due to the accumulation of fluid in the surrounding brain tissue.\n* label 4: Gd-enhancing tumor (Needs to be converted to 3) (Visible in T1ce): This class represents the region of the tumor that enhances with the administration of contrast agent.","metadata":{}},{"cell_type":"code","source":"my_tarfile = tarfile.open('/kaggle/input/brats-2021-task1/BraTS2021_Training_Data.tar')\n\nindex = my_tarfile.getnames()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T20:55:13.884662Z","iopub.execute_input":"2023-03-16T20:55:13.885074Z","iopub.status.idle":"2023-03-16T20:56:19.341448Z","shell.execute_reply.started":"2023-03-16T20:55:13.885036Z","shell.execute_reply":"2023-03-16T20:56:19.339939Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"index[: 8]","metadata":{"execution":{"iopub.status.busy":"2023-03-16T20:58:41.360157Z","iopub.execute_input":"2023-03-16T20:58:41.360558Z","iopub.status.idle":"2023-03-16T20:58:41.367927Z","shell.execute_reply.started":"2023-03-16T20:58:41.360521Z","shell.execute_reply":"2023-03-16T20:58:41.366725Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['.',\n './.DS_Store',\n './BraTS2021_00000',\n './BraTS2021_00000/BraTS2021_00000_flair.nii.gz',\n './BraTS2021_00000/BraTS2021_00000_seg.nii.gz',\n './BraTS2021_00000/BraTS2021_00000_t1.nii.gz',\n './BraTS2021_00000/BraTS2021_00000_t1ce.nii.gz',\n './BraTS2021_00000/BraTS2021_00000_t2.nii.gz']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Basic Visualization","metadata":{}},{"cell_type":"code","source":"!pip install itkwidgets","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VisualizePatientData:\n    def __init__(self, patient_data_folder, img_type_id):\n        self.patient_data_list = sorted(glob.glob(os.path.join(patient_data_folder, \"*\")))\n        self.image_types = [\"flair\", \"seg\", \"t1\", \"t1ce\", \"t2\"]\n        self.cmap_list = [\"gray\", \"BuPu\", \"gray\", \"gray\", \"gray\"]\n        self.i = img_type_id\n        self.fig = plt.figure(figsize=(1, 1));\n    \n    def visualize_brain_scans(self, cube_path):\n        def create_display(layer):\n            self.fig.add_subplot(3, 2, self.i + 1)\n            plt.imshow(self.scans[:, :, layer], cmap=self.cmap_list[self.i]);\n            plt.axis('off')\n            return layer\n        self.scans = np.asarray(nib.load(cube_path).get_fdata())\n        print(seld.scans.shape)\n        interact(create_display, layer=(0, self.scans.shape[2] - 1));\n\n    def __call__(self, idx):        \n        data_path = os.path.join(self.patient_data_list[idx], \"BraTS20_Training_%03d_%s.nii\" % (idx + 1, self.image_types[self.i]))\n        self.visualize_brain_scans(data_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_data_folder = \"/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/MICCAI_BraTS2020_TrainingData\"\nexample_patient_id = 0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualizer_flair = VisualizePatientData(patient_data_folder, 0)\nvisualizer_flair(example_patient_id)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualizer_seg = VisualizePatientData(patient_data_folder, 1)\nvisualizer_seg(example_patient_id)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualizer_t1 = VisualizePatientData(patient_data_folder, 2)\nvisualizer_t1(example_patient_id)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualizer_t1ce = VisualizePatientData(patient_data_folder, 3)\nvisualizer_t1ce(example_patient_id)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualizer_t2 = VisualizePatientData(patient_data_folder, 4)\nvisualizer_t2(example_patient_id)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Segmentation Classes study","metadata":{}},{"cell_type":"code","source":"import nibabel as nib\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\nimport os\nfrom tqdm import tqdm\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom scipy.ndimage.measurements import label, center_of_mass","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_data_folder = \"/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/MICCAI_BraTS2020_TrainingData\"\npatient_data_list = sorted(glob.glob(os.path.join(patient_data_folder, \"*\")))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"core_tumor = []\nperitumoral_tissue = []\nenhancing_tumor = []\ncube_size = 240 * 240 * 155\nfor i in tqdm(range(len(patient_data_list) - 2)):\n    if i == 354:\n        patient_label_data_path = \"/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/W39_1998.09.19_Segm.nii\"\n    else:\n        patient_label_data_path = os.path.join(patient_data_list[i], \"BraTS20_Training_%03d_seg.nii\" % (i + 1))\n    patient_label_data = nib.load(patient_label_data_path).get_fdata()\n    core_tumor.append((len(np.where(patient_label_data == 1)[0]) / cube_size) * 100)\n    peritumoral_tissue.append((len(np.where(patient_label_data == 2)[0]) / cube_size) * 100)\n    enhancing_tumor.append((len(np.where(patient_label_data == 4)[0]) / cube_size) * 100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = [core_tumor, peritumoral_tissue, enhancing_tumor]\ndata_string = [\"core_tumor\", \"peritumoral_tissue\", \"enhancing_tumor\"] \nfig = plt.figure(figsize=(12, 12))\nfor i in range(4):\n    plt.subplot(2, 2, i + 1)\n    if i == 3:\n        plt.bar(x=[0, 1, 2], height=[np.average(core_tumor), np.average(peritumoral_tissue), np.average(enhancing_tumor)])\n        plt.title(\"Average volume of %s, %s, %s\" % (data_string[0], data_string[1], data_string[2]))\n    else:    \n        plt.hist(data[i])\n        plt.title(\"Distribution of volume of %s\" % data_string[i])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_brain_scans(scans):\n    def create_display(layer):\n        plt.imshow(scans[:, :, layer], cmap=\"BuPu\");\n        plt.axis('off')\n        return layer\n    interact(create_display, layer=(0, scans.shape[2] - 1));","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_centroid_volume_largest_component(seg_labels, label_id):\n    seg_labels_core = np.asarray(seg_labels == label_id, dtype=np.uint8)\n    labels, num_labels = label(seg_labels_core)\n    volumes = []\n    for i in range(1, num_labels + 1):\n        volume = np.sum(labels == i)\n        volumes.append(volume)\n    volumes = np.array(volumes)\n    if len(volumes):\n        largest_components_id = np.argmax(volumes, -1) + 1\n        centroid_i = center_of_mass(seg_labels_core, labels=labels, index=largest_components_id)\n        volume_i = volumes[largest_components_id - 1]\n        return centroid_i, volume_i\n    else:\n        return None, None","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def centroid_volume_correlation(label_id):\n    centroids = []\n    volumes = []\n    for i in tqdm(range(len(patient_data_list) - 2)):\n        if i == 354:\n            patient_label_data_path = \"/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/W39_1998.09.19_Segm.nii\"\n        else:\n            patient_label_data_path = os.path.join(patient_data_list[i], \"BraTS20_Training_%03d_seg.nii\" % (i + 1))\n        patient_label_data = nib.load(patient_label_data_path).get_fdata()\n        centroid_i, volume_i = compute_centroid_volume_largest_component(patient_label_data, label_id)\n        if volume_i is None:\n            continue\n        centroids.append(centroid_i)\n        volumes.append(volume_i)\n    return centroids, volumes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_id = 1\ncentroids, volumes = centroid_volume_correlation(label_id)\ncentroids = np.array(centroids)\nvolumes = np.array(volumes)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(120, 120))\nax = fig.add_subplot(111, projection='3d')\nax.scatter(centroids[:,0], centroids[:,1], centroids[:,2], s=volumes, c=volumes, cmap='BuPu')\nax.set_xlabel('X Centroid', fontsize=100)\nax.set_ylabel('Y Centroid', fontsize=100)\nax.set_zlabel('Z Centroid', fontsize=100)\nax.set_title('Correlation between Centroid and Volume', fontsize=100)\n# cbar = plt.colorbar()\n# cbar.set_label('Volume')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_id = 2\ncentroids, volumes = centroid_volume_correlation(label_id)\ncentroids = np.array(centroids)\nvolumes = np.array(volumes)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(120, 120))\nax = fig.add_subplot(111, projection='3d')\nax.scatter(centroids[:,0], centroids[:,1], centroids[:,2], s=volumes, c=volumes, cmap='BuPu')\nax.set_xlabel('X Centroid', fontsize=100)\nax.set_ylabel('Y Centroid', fontsize=100)\nax.set_zlabel('Z Centroid', fontsize=100)\nax.set_title('Correlation between Centroid and Volume', fontsize=100)\n# cbar = plt.colorbar()\n# cbar.set_label('Volume')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_id = 4\ncentroids, volumes = centroid_volume_correlation(label_id)\ncentroids = np.array(centroids)\nvolumes = np.array(volumes)\nfig = plt.figure(figsize=(120, 120))\nax = fig.add_subplot(111, projection='3d')\nax.scatter(centroids[:,0], centroids[:,1], centroids[:,2], s=volumes, c=volumes, cmap='BuPu')\nax.set_xlabel('X Centroid', fontsize=100)\nax.set_ylabel('Y Centroid', fontsize=100)\nax.set_zlabel('Z Centroid', fontsize=100)\nax.set_title('Correlation between Centroid and Volume', fontsize=100)\n# cbar = plt.colorbar()\n# cbar.set_label('Volume')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating two splits from a dataset","metadata":{}},{"cell_type":"code","source":"import random\nimport glob\nimport os\nfrom tqdm import tqdm\nimport nibabel as nib\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_class_volumes(patient_folder_list):\n    core_tumor = []\n    peritumoral_tissue = []\n    enhancing_tumor = []\n    cube_size = 240 * 240 * 155\n    for i in tqdm(patient_folder_list):\n        if i.endswith(\"355\"):\n            patient_label_data_path = \"/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/W39_1998.09.19_Segm.nii\"\n        else:\n            patient_label_data_path = os.path.join(i, \"BraTS20_Training_%03d_seg.nii\" % int(i.split(\"_\")[-1]))\n        patient_label_data = nib.load(patient_label_data_path).get_fdata()\n        core_tumor.append((len(np.where(patient_label_data == 1)[0]) / cube_size) * 100)\n        peritumoral_tissue.append((len(np.where(patient_label_data == 2)[0]) / cube_size) * 100)\n        enhancing_tumor.append((len(np.where(patient_label_data == 4)[0]) / cube_size) * 100)\n    return core_tumor, peritumoral_tissue, enhancing_tumor","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_class_distributions(data):\n    core_tumor, peritumoral_tissue, enhancing_tumor = data\n    data_string = [\"core_tumor\", \"peritumoral_tissue\", \"enhancing_tumor\"] \n    fig = plt.figure(figsize=(12, 12))\n    for i in range(4):\n        plt.subplot(2, 2, i + 1)\n        if i == 3:\n            plt.bar(x=[0, 1, 2], height=[np.average(core_tumor), np.average(peritumoral_tissue), np.average(enhancing_tumor)])\n            plt.title(\"Average volume of %s, %s, %s\" % (data_string[0], data_string[1], data_string[2]))\n        else:    \n            plt.hist(data[i])\n            plt.title(\"Distribution of volume of %s\" % data_string[i])\n    return np.average(core_tumor), np.average(peritumoral_tissue), np.average(enhancing_tumor)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_two_splits(data_list, split_ratio):\n    continue_loop = True\n    while continue_loop:\n        list1 = random.sample(data_list, int(0.8 * len(data_list)))\n        list2 = [i for i in data_list if i not in list1]\n        list1_volumes = compute_class_volumes(list1)\n        list2_volumes = compute_class_volumes(list2)\n        list1_volumes_averages = [np.average(i) for i in list1_volumes]\n        list2_volumes_averages = [np.average(i) for i in list2_volumes]\n        overall_averages = [np.average(i + j) for i, j in zip(list1_volumes_averages, list2_volumes_averages)]\n        list1_class_proportion = np.divide(list1_volumes_averages, np.sum(list1_volumes_averages))\n        list2_class_proportion = np.divide(list2_volumes_averages, np.sum(list2_volumes_averages))\n        overall_class_proportion = np.divide(overall_averages, np.sum(overall_averages))\n        print(\"Current split data: \", list1_class_proportion, list2_class_proportion)\n        if ((overall_class_proportion[0] - 0.01 <= list1_class_proportion[0] <= overall_class_proportion[0] + 0.01) and\n           (overall_class_proportion[1] - 0.01 <= list1_class_proportion[1] <= overall_class_proportion[1] + 0.01) and\n           (overall_class_proportion[2] - 0.01 <= list1_class_proportion[2] <= overall_class_proportion[2] + 0.01) and\n           (overall_class_proportion[0] - 0.01 <= list2_class_proportion[0] <= overall_class_proportion[0] + 0.01) and\n           (overall_class_proportion[1] - 0.01 <= list2_class_proportion[1] <= overall_class_proportion[1] + 0.01) and\n           (overall_class_proportion[2] - 0.01 <= list2_class_proportion[2] <= overall_class_proportion[2] + 0.01)):\n                return list1, list2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_data_folder = \"/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/MICCAI_BraTS2020_TrainingData\"\npatient_data_list = sorted(glob.glob(os.path.join(patient_data_folder, \"*\")))[: -2]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_split, test_split = compute_two_splits(patient_data_list, 0.8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_volumes = compute_class_volumes(train_split)\ntest_volumes = compute_class_volumes(test_split)\nvisualize_class_distributions(train_volumes)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_class_distributions(test_volumes)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_final, validation = compute_two_splits(train_split, 0.8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_final_volumes = compute_class_volumes(training_final)\nvalidation_volumes = compute_class_volumes(validation)\nvisualize_class_distributions(train_final_volumes)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_class_distributions(validation_volumes)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Generator","metadata":{}},{"cell_type":"code","source":"import torch\nimport nibabel as nib\nimport numpy as np\nimport os\nimport glob\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2023-03-16T23:22:16.375825Z","iopub.execute_input":"2023-03-16T23:22:16.376162Z","iopub.status.idle":"2023-03-16T23:22:17.814298Z","shell.execute_reply.started":"2023-03-16T23:22:16.376134Z","shell.execute_reply":"2023-03-16T23:22:17.813292Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class BTSDataset(torch.utils.data.Dataset):\n    def __init__(self, patient_data_list, no_classes=4):\n        self.patient_flair_scans_list = [glob.glob(os.path.join(i, \"*_flair.nii\"))[0] for i in patient_data_list] \n        self.patient_t1ce_scans_list = [glob.glob(os.path.join(i, \"*_t1ce.nii\"))[0] for i in patient_data_list] \n        self.patient_t2_scans_list = [glob.glob(os.path.join(i, \"*_t2.nii\"))[0] for i in patient_data_list] \n        self.patient_seg_scans_list = [glob.glob(os.path.join(i, \"*_seg.nii\"))[0] for i in patient_data_list] \n        self.transform = transforms.ToTensor()\n        self.no_classes = no_classes\n    \n    def __len__(self):\n        return len(self.patient_flair_scans_list)\n    \n    def __getitem__(self, idx):\n        t1ce_scan = self.transform(np.asarray(nib.load(self.patient_t1ce_scans_list[idx]).get_fdata()))\n        t2_scan = self.transform(np.asarray(nib.load(self.patient_t2_scans_list[idx]).get_fdata()))\n        flair_scan = self.transform(np.asarray(nib.load(self.patient_flair_scans_list[idx]).get_fdata()))\n        seg_label = np.asarray(nib.load(self.patient_seg_scans_list[idx]).get_fdata())\n        seg_label[seg_label == 4] = 3\n        seg_label = self.transform(seg_label)\n        seg_label_ohe = torch.nn.functional.one_hot(seg_label.to(torch.int64), self.no_classes)\n        seg_label_ohe = torch.moveaxis(seg_label_ohe, -1, 0)\n        image_scans_stacked = torch.stack([t1ce_scan, t2_scan, flair_scan])\n        return image_scans_stacked, seg_label_ohe        ","metadata":{"execution":{"iopub.status.busy":"2023-03-16T23:22:17.816350Z","iopub.execute_input":"2023-03-16T23:22:17.816753Z","iopub.status.idle":"2023-03-16T23:22:17.826966Z","shell.execute_reply.started":"2023-03-16T23:22:17.816728Z","shell.execute_reply":"2023-03-16T23:22:17.825931Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/MICCAI_BraTS2020_TrainingData\"\nfolder_list = sorted(glob.glob(os.path.join(path, \"*\")))\nfolder_list = [i for i in folder_list if os.path.isdir(i)]\nfolder_list.pop(354)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T23:22:17.829949Z","iopub.execute_input":"2023-03-16T23:22:17.830268Z","iopub.status.idle":"2023-03-16T23:22:17.887421Z","shell.execute_reply.started":"2023-03-16T23:22:17.830230Z","shell.execute_reply":"2023-03-16T23:22:17.886111Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355'"},"metadata":{}}]},{"cell_type":"code","source":"dataset = BTSDataset(folder_list)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T23:22:19.222250Z","iopub.execute_input":"2023-03-16T23:22:19.223679Z","iopub.status.idle":"2023-03-16T23:22:21.085973Z","shell.execute_reply.started":"2023-03-16T23:22:19.223636Z","shell.execute_reply":"2023-03-16T23:22:21.085260Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"ex_idx = 0\nex_img, ex_label = dataset[ex_idx]\nex_img.shape, ex_label.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-16T23:22:21.089465Z","iopub.execute_input":"2023-03-16T23:22:21.090442Z","iopub.status.idle":"2023-03-16T23:22:22.090807Z","shell.execute_reply.started":"2023-03-16T23:22:21.090404Z","shell.execute_reply":"2023-03-16T23:22:22.089945Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(torch.Size([3, 155, 240, 240]), torch.Size([4, 155, 240, 240]))"},"metadata":{}}]},{"cell_type":"markdown","source":"# Training setup","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, loss, optimizer, number_of_epochs, weights_save_folder):\n        self.loss = loss\n        self.number_of_epochs = number_of_epochs\n        self.model = model\n        self.model.to(\"cuda\")\n        self.optimizer = optimizer\n        self.best_model_weights = None\n        self.weights_save_folder = weights_save_folder\n\n    def __call__(self, training_dataloader, validation_dataloader):\n        average_val_loss = 10 ** 6\n        for i in range(self.number_of_epochs):\n            print(\"Epoch number: \", i)\n            for image, label in tqdm(training_dataloader):\n                self.optimizer.zero_grad()\n                probabilities = self.model(image.cuda().to(device))\n                self.loss(probabilities, label.cuda().to(device))\n                self.optimizer.step()\n                del image, label, probabilities\n            validation_loss = []\n            for image, label in tqdm(validation_dataloader):\n                with torch.no_grad():\n                    image = image.cuda().to(device)\n                    label = label.cuda().to(device)\n                    probabilities = self.model(image)\n                    validation_loss.append(self.loss(probabilities, label).cpu())\n                    del probabilities, image, label\n            if np.average(validation_loss) < average_val_loss:\n                self.best_model_weights = self.model.state_dict()\n                average_val_loss = np.average(validation_loss)\n                torch.save(self.model.state_dict(), os.path.join(self.weights_save_folder, 'model_weights_%d.pth' % i))\n        return self.best_model_weights, self.model.to(\"cpu\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"def generate_predictions(model, test_dataloader):\n    model.to(device)\n    test_predictions = []\n    test_labels = []\n    with torch.no_grad():\n        for image, label in test_dataloader:\n            image = image.cuda().to(device)\n            label = label.cpu().numpy()\n            label = np.argmax(label, -1)\n            probabilities = model(image)\n            test_predictions.extend(np.argmax(probabilities.cpu(), -1))\n            test_labels.extend(label)\n            del probabilities, label\n    return test_predictions, test_labels  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Need to add code for computing dice score or other metrics","metadata":{},"execution_count":null,"outputs":[]}]}